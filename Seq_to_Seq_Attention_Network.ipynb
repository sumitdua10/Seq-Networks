{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq to Seq Attention Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumitdua10/Seq-Networks/blob/master/Seq_to_Seq_Attention_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pORSUqF1ExT-",
        "colab_type": "code",
        "outputId": "3a5491b3-b92d-4d09-a0fa-923a9789454d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cfb676d9-9df6-4f96-9c28-0115a5307701\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cfb676d9-9df6-4f96-9c28-0115a5307701\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving book2.txt to book2.txt\n",
            "User uploaded file \"book2.txt\" with length 20298 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xy_CnD7mE_uv",
        "colab_type": "code",
        "outputId": "19621d6b-1b4c-4637-b0d0-ad7b165cc362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(fn, delimiter = '\\t')\n",
        "print(df.shape)\n",
        "print(df[:5])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(797, 4)\n",
            "           X  Date  Month  Year\n",
            "0  18/9/1970    18      9  1970\n",
            "1  15/7/1968    15      7  1968\n",
            "2  23/5/1963    23      5  1963\n",
            "3  27/7/2007    27      7  2007\n",
            "4  16/6/1995    16      6  1995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EEMXGr3WFKyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Code to get reproducible results\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM, GRU, Input, Embedding, Flatten, RepeatVector, Dropout\n",
        "from keras.layers import Reshape, Add, Multiply, Concatenate, GlobalMaxPooling2D, GlobalMaxPooling1D, Dot\n",
        "from keras.activations import softmax\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "rn.seed(12345)\n",
        "\n",
        "# Force TensorFlow to use single thread.\n",
        "# Multiple threads are a potential source of non-reproducible results.\n",
        "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "from keras import backend as K\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZV2TBAoGdfrZ",
        "colab_type": "code",
        "outputId": "547cddc8-0dd6-4270-fb34-e41aa6f23bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "data = open(fn, 'r').read()\n",
        "data= data.lower()\n",
        "chars = list(set(data))\n",
        "#print(data[1:50])\n",
        "\n",
        "data_size, VOCAB_LEN = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters(vocab length)in your data.' % (data_size, VOCAB_LEN))\n",
        "\n",
        "#2. Global variables\n",
        "MAX_INPUT_SEQ_LEN = len(max(df['X']))\n",
        "OUTPUT_SIZE = 4 # For year only (4-digit)\n",
        "m = df.shape[0]\n",
        "\n",
        "print(\"Max Length \", MAX_INPUT_SEQ_LEN)\n",
        "\n",
        "#3. Create a dictionary & vocab size\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
        "print(\"Integer to character dict mapping:\\n\",ix_to_char)\n",
        "print(\"\\n Character to Integer dict mapping:\")\n",
        "print(char_to_ix)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 19501 total characters and 40 unique characters(vocab length)in your data.\n",
            "Max Length  29\n",
            "Integer to character dict mapping:\n",
            " {0: '\\t', 1: '\\n', 2: ' ', 3: ',', 4: '-', 5: '/', 6: '0', 7: '1', 8: '2', 9: '3', 10: '4', 11: '5', 12: '6', 13: '7', 14: '8', 15: '9', 16: ':', 17: 'a', 18: 'b', 19: 'c', 20: 'd', 21: 'e', 22: 'f', 23: 'g', 24: 'h', 25: 'i', 26: 'j', 27: 'l', 28: 'm', 29: 'n', 30: 'o', 31: 'p', 32: 'r', 33: 's', 34: 't', 35: 'u', 36: 'v', 37: 'w', 38: 'x', 39: 'y'}\n",
            "\n",
            " Character to Integer dict mapping:\n",
            "{'\\t': 0, '\\n': 1, ' ': 2, ',': 3, '-': 4, '/': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, ':': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'l': 27, 'm': 28, 'n': 29, 'o': 30, 'p': 31, 'r': 32, 's': 33, 't': 34, 'u': 35, 'v': 36, 'w': 37, 'x': 38, 'y': 39}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4JexW0HoVpq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#5. Create on hot encoding of size x = m X SEQ_L X VOCAB_LEN and y = m X OUTPUT_SIZE * VOCAB_LEN\n",
        "\n",
        "x = np.zeros(shape = (m, MAX_INPUT_SEQ_LEN, VOCAB_LEN))\n",
        "y = np.zeros(shape=(m,OUTPUT_SIZE, VOCAB_LEN))\n",
        "\n",
        "#decoder input. This will be used as Teacher enforcing during training. \n",
        "# It will be y shifted by one character so that y[0] goes as input to 2nd decoder cell and so on. First input to decoder cell will be 0\n",
        "# and output h,c from encoder LSTM will be used as initial states for first cell of decoder model.\n",
        "de_x  = np.zeros(shape=(m,OUTPUT_SIZE, VOCAB_LEN))\n",
        "\n",
        "df['X'] = df['X'].str.lower()\n",
        "for i in range(m):\n",
        "    for j,k in enumerate(df['X'][i]):\n",
        "      try:\n",
        "        x[i][j][char_to_ix[k]] = 1\n",
        "      except:\n",
        "        print(\"i {} j {} k {}\".format( i, j, k))\n",
        "        \n",
        "    for a,b in enumerate(str(df['Year'][i])):\n",
        "      try:\n",
        "        \n",
        "        y[i][a][char_to_ix[b]] = 1\n",
        "        \n",
        "        \n",
        "        if a<OUTPUT_SIZE-1:\n",
        "          de_x[i][a+1][char_to_ix[b]] = 1\n",
        "        \n",
        "      except:\n",
        "        print(\"i {} a {} b {}\".format( i, a, b))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UaN8aNrEAi14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7925f497-4db3-4f0b-8137-e62de680d0f9"
      },
      "cell_type": "code",
      "source": [
        "#Test the encoding:\n",
        "\n",
        "print(df['X'][0])\n",
        "pos = np.argmax(x[0][0])\n",
        "print(\"First character should match with first character of date\")\n",
        "print(ix_to_char[pos])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/9/1970\n",
            "First character should match with first character of date\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EnzFqTLGkZpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2740
        },
        "outputId": "9c9c3101-0ea4-41cf-8530-8910bca3e3db"
      },
      "cell_type": "code",
      "source": [
        "activation_size=96\n",
        "nn_units = 64\n",
        "from keras.layers import Bidirectional\n",
        "from keras import optimizers\n",
        "import keras.backend as K\n",
        "\n",
        "en_inputs = Input(shape=(MAX_INPUT_SEQ_LEN, VOCAB_LEN,))\n",
        "\n",
        "fn = Bidirectional(LSTM(activation_size,  activation='tanh', return_state=True, return_sequences = True, dropout = 0.5))(en_inputs)\n",
        "print(len(fn))\n",
        "for mm in fn:\n",
        "   print(mm.shape)\n",
        "o = fn[0]\n",
        "h = fn[1]\n",
        "c = fn[2]\n",
        "print(\" o shape of encoder \", o.shape)\n",
        "print(\" h shape of encoder \", h.shape)\n",
        "\n",
        "initial_o_input = Input(shape=(activation_size,))\n",
        "initial_o = initial_o_input\n",
        "initial_h = initial_o_input\n",
        "initial_c = initial_o_input\n",
        "#initial_o = initial_o_input\n",
        "print(\"s-1 shape of decoder \", initial_s)\n",
        "\n",
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e / s\n",
        "  return softmax(x,axis=-2)\n",
        "\n",
        "output= []\n",
        "\n",
        "\n",
        "#repeat = RepeatVector(MAX_INPUT_SEQ_LEN)\n",
        "#concats = Concatenate()\n",
        "#dense_20_param = Dense(20, activation ='relu', name = \"dense_20_param_{}\".format(i))\n",
        "#dense_1_param = Dense(1, activation=softmax_over_time, name=\"dense_1_param_{}\".format(i))\n",
        "\n",
        "def one_step_attention():\n",
        " \n",
        "  initial_s = RepeatVector(MAX_INPUT_SEQ_LEN)(initial_h)\n",
        "  #initial_s = repeat(initial_h)  \n",
        "  concat = Concatenate()([initial_s, o])\n",
        "  #concat = concats([initial_s,o])\n",
        "  \n",
        "  print(\"O shape before going into NN \", concat)\n",
        "  \n",
        "  nn = Dense(20, activation ='relu', name = \"dense_20_param_{}\".format(i))(concat)\n",
        "  #nn = dense_20_param(concat)\n",
        "  print(\"nn after 20 dense\", nn )\n",
        "  nn = Dropout(0.5)(nn)\n",
        "  \n",
        "  #nn = Dense(1, activation=softmax_over_time)(nn)\n",
        "  nn = Dense(1, activation=softmax_over_time, name=\"dense_1_param_{}\".format(i))(nn)\n",
        "  #nn = dense_1_param(nn)\n",
        "  #print(\"Neural network output \", nn)\n",
        "  #nn = softmax(nn, axis=-2)\n",
        "  print(\"After appplying nuerual network \", nn)\n",
        "  print(\" o shape before dot \", o.shape)\n",
        "  context = Dot(axes=1)([nn,o])\n",
        "  print(\" context shape after dot \", context.shape)\n",
        "  #context = Reshape((activation_size,))(context)\n",
        "  #print(\" context after reshape \", context.shape)\n",
        "  return context\n",
        "\n",
        "for i in range(OUTPUT_SIZE):\n",
        "\n",
        "  context = one_step_attention()\n",
        "  initial_oo = Reshape((1,activation_size,))(initial_o)\n",
        "  decoder_o = Concatenate()([context, initial_oo])\n",
        "  at_o, at_h, at_c = LSTM(activation_size, activation = 'tanh', return_state=True,return_sequences=False, dropout = 0.5)(decoder_o, initial_state=[initial_h, initial_c])\n",
        "  z = Dense(VOCAB_LEN, activation = 'softmax')(at_o)\n",
        "  print(\" Z dimension \", z)\n",
        "  output.append(z)\n",
        "  \n",
        "  print(\"output Dimensions \", output)\n",
        "  \n",
        "  print(\"at_o: \", at_o)\n",
        "  print(\"at_h \", at_h)\n",
        "  initial_h = at_h\n",
        "  initial_c = at_c\n",
        "  initial_o = at_o\n",
        "\n",
        "model = Model([en_inputs, initial_o_input], output)\n",
        "print(model.summary())\n",
        "\n",
        "sgd = optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(?, ?, 192)\n",
            "(?, 96)\n",
            "(?, 96)\n",
            "(?, 96)\n",
            "(?, 96)\n",
            " o shape of encoder  (?, ?, 192)\n",
            " h shape of encoder  (?, 96)\n",
            "s-1 shape of decoder  Tensor(\"input_106:0\", shape=(?, 96), dtype=float32)\n",
            "O shape before going into NN  Tensor(\"concatenate_177/concat:0\", shape=(?, 29, 288), dtype=float32)\n",
            "nn after 20 dense Tensor(\"dense_20_param_0_36/Relu:0\", shape=(?, 29, 20), dtype=float32)\n",
            "After appplying nuerual network  Tensor(\"dense_1_param_0_37/truediv:0\", shape=(?, 29, 1), dtype=float32)\n",
            " o shape before dot  (?, ?, 192)\n",
            " context shape after dot  (?, 1, 192)\n",
            " Z dimension  Tensor(\"dense_231/Softmax:0\", shape=(?, 40), dtype=float32)\n",
            "output Dimensions  [<tf.Tensor 'dense_231/Softmax:0' shape=(?, 40) dtype=float32>]\n",
            "at_o:  Tensor(\"lstm_182/TensorArrayReadV3:0\", shape=(?, 96), dtype=float32)\n",
            "at_h  Tensor(\"lstm_182/while/Exit_2:0\", shape=(?, 96), dtype=float32)\n",
            "O shape before going into NN  Tensor(\"concatenate_179/concat:0\", shape=(?, 29, 288), dtype=float32)\n",
            "nn after 20 dense Tensor(\"dense_20_param_1_14/Relu:0\", shape=(?, 29, 20), dtype=float32)\n",
            "After appplying nuerual network  Tensor(\"dense_1_param_1_15/truediv:0\", shape=(?, 29, 1), dtype=float32)\n",
            " o shape before dot  (?, ?, 192)\n",
            " context shape after dot  (?, 1, 192)\n",
            " Z dimension  Tensor(\"dense_232/Softmax:0\", shape=(?, 40), dtype=float32)\n",
            "output Dimensions  [<tf.Tensor 'dense_231/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_232/Softmax:0' shape=(?, 40) dtype=float32>]\n",
            "at_o:  Tensor(\"lstm_183/TensorArrayReadV3:0\", shape=(?, 96), dtype=float32)\n",
            "at_h  Tensor(\"lstm_183/while/Exit_2:0\", shape=(?, 96), dtype=float32)\n",
            "O shape before going into NN  Tensor(\"concatenate_181/concat:0\", shape=(?, 29, 288), dtype=float32)\n",
            "nn after 20 dense Tensor(\"dense_20_param_2_14/Relu:0\", shape=(?, 29, 20), dtype=float32)\n",
            "After appplying nuerual network  Tensor(\"dense_1_param_2_15/truediv:0\", shape=(?, 29, 1), dtype=float32)\n",
            " o shape before dot  (?, ?, 192)\n",
            " context shape after dot  (?, 1, 192)\n",
            " Z dimension  Tensor(\"dense_233/Softmax:0\", shape=(?, 40), dtype=float32)\n",
            "output Dimensions  [<tf.Tensor 'dense_231/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_232/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_233/Softmax:0' shape=(?, 40) dtype=float32>]\n",
            "at_o:  Tensor(\"lstm_184/TensorArrayReadV3:0\", shape=(?, 96), dtype=float32)\n",
            "at_h  Tensor(\"lstm_184/while/Exit_2:0\", shape=(?, 96), dtype=float32)\n",
            "O shape before going into NN  Tensor(\"concatenate_183/concat:0\", shape=(?, 29, 288), dtype=float32)\n",
            "nn after 20 dense Tensor(\"dense_20_param_3_18/Relu:0\", shape=(?, 29, 20), dtype=float32)\n",
            "After appplying nuerual network  Tensor(\"dense_1_param_3_15/truediv:0\", shape=(?, 29, 1), dtype=float32)\n",
            " o shape before dot  (?, ?, 192)\n",
            " context shape after dot  (?, 1, 192)\n",
            " Z dimension  Tensor(\"dense_234/Softmax:0\", shape=(?, 40), dtype=float32)\n",
            "output Dimensions  [<tf.Tensor 'dense_231/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_232/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_233/Softmax:0' shape=(?, 40) dtype=float32>, <tf.Tensor 'dense_234/Softmax:0' shape=(?, 40) dtype=float32>]\n",
            "at_o:  Tensor(\"lstm_185/TensorArrayReadV3:0\", shape=(?, 96), dtype=float32)\n",
            "at_h  Tensor(\"lstm_185/while/Exit_2:0\", shape=(?, 96), dtype=float32)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_118 (InputLayer)          (None, 96)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_117 (InputLayer)          (None, 29, 40)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_145 (RepeatVector (None, 29, 96)       0           input_118[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 29, 192), (N 105216      input_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 29, 288)      0           repeat_vector_145[0][0]          \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_20_param_0 (Dense)        (None, 29, 20)       5780        concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 29, 20)       0           dense_20_param_0[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_param_0 (Dense)         (None, 29, 1)        21          dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_140 (Dot)                   (None, 1, 192)       0           dense_1_param_0[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_114 (Reshape)           (None, 1, 96)        0           input_118[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 1, 288)       0           dot_140[0][0]                    \n",
            "                                                                 reshape_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_182 (LSTM)                 [(None, 96), (None,  147840      concatenate_178[0][0]            \n",
            "                                                                 input_118[0][0]                  \n",
            "                                                                 input_118[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_146 (RepeatVector (None, 29, 96)       0           lstm_182[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 29, 288)      0           repeat_vector_146[0][0]          \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_20_param_1 (Dense)        (None, 29, 20)       5780        concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 29, 20)       0           dense_20_param_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_param_1 (Dense)         (None, 29, 1)        21          dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_141 (Dot)                   (None, 1, 192)       0           dense_1_param_1[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_115 (Reshape)           (None, 1, 96)        0           lstm_182[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_180 (Concatenate)   (None, 1, 288)       0           dot_141[0][0]                    \n",
            "                                                                 reshape_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_183 (LSTM)                 [(None, 96), (None,  147840      concatenate_180[0][0]            \n",
            "                                                                 lstm_182[0][1]                   \n",
            "                                                                 lstm_182[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_147 (RepeatVector (None, 29, 96)       0           lstm_183[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_181 (Concatenate)   (None, 29, 288)      0           repeat_vector_147[0][0]          \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_20_param_2 (Dense)        (None, 29, 20)       5780        concatenate_181[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 29, 20)       0           dense_20_param_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_param_2 (Dense)         (None, 29, 1)        21          dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_142 (Dot)                   (None, 1, 192)       0           dense_1_param_2[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_116 (Reshape)           (None, 1, 96)        0           lstm_183[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_182 (Concatenate)   (None, 1, 288)       0           dot_142[0][0]                    \n",
            "                                                                 reshape_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_184 (LSTM)                 [(None, 96), (None,  147840      concatenate_182[0][0]            \n",
            "                                                                 lstm_183[0][1]                   \n",
            "                                                                 lstm_183[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_148 (RepeatVector (None, 29, 96)       0           lstm_184[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_183 (Concatenate)   (None, 29, 288)      0           repeat_vector_148[0][0]          \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_20_param_3 (Dense)        (None, 29, 20)       5780        concatenate_183[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 29, 20)       0           dense_20_param_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_param_3 (Dense)         (None, 29, 1)        21          dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_143 (Dot)                   (None, 1, 192)       0           dense_1_param_3[0][0]            \n",
            "                                                                 bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_117 (Reshape)           (None, 1, 96)        0           lstm_184[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_184 (Concatenate)   (None, 1, 288)       0           dot_143[0][0]                    \n",
            "                                                                 reshape_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_185 (LSTM)                 [(None, 96), (None,  147840      concatenate_184[0][0]            \n",
            "                                                                 lstm_184[0][1]                   \n",
            "                                                                 lstm_184[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_231 (Dense)               (None, 40)           3880        lstm_182[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_232 (Dense)               (None, 40)           3880        lstm_183[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_233 (Dense)               (None, 40)           3880        lstm_184[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_234 (Dense)               (None, 40)           3880        lstm_185[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 735,300\n",
            "Trainable params: 735,300\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SbNEbFE_8YWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xvSTeNG3y9Rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        },
        "outputId": "5e061818-8b15-4a18-e460-8caf153cf3d7"
      },
      "cell_type": "code",
      "source": [
        "temp_x = np.zeros(shape = ([m, activation_size]))\n",
        "\n",
        "\n",
        "#print(temp_x[0][0][:4])\n",
        "print(y[:,0,:].shape)\n",
        "\n",
        "model.fit([x,temp_x], [y[:,0,:],y[:,1,:],y[:,2,:],y[:,3,:]], epochs= 50, verbose = 1, validation_split = 0.2)  "
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(797, 40)\n",
            "Train on 637 samples, validate on 160 samples\n",
            "Epoch 1/100\n",
            "637/637 [==============================] - 24s 38ms/step - loss: 8.6405 - dense_231_loss: 1.5655 - dense_232_loss: 1.4519 - dense_233_loss: 2.8518 - dense_234_loss: 2.7713 - dense_231_acc: 0.8069 - dense_232_acc: 0.8085 - dense_233_acc: 0.1287 - dense_234_acc: 0.1036 - val_loss: 5.7815 - val_dense_231_loss: 0.4901 - val_dense_232_loss: 0.4924 - val_dense_233_loss: 2.3527 - val_dense_234_loss: 2.4463 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.0500\n",
            "Epoch 2/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.6025 - dense_231_loss: 0.4478 - dense_232_loss: 0.4491 - dense_233_loss: 2.3606 - dense_234_loss: 2.3450 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1429 - dense_234_acc: 0.1099 - val_loss: 5.5401 - val_dense_231_loss: 0.4642 - val_dense_232_loss: 0.4652 - val_dense_233_loss: 2.2863 - val_dense_234_loss: 2.3244 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1062\n",
            "Epoch 3/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.5288 - dense_231_loss: 0.4373 - dense_232_loss: 0.4386 - dense_233_loss: 2.3174 - dense_234_loss: 2.3354 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1554 - dense_234_acc: 0.1068 - val_loss: 5.5355 - val_dense_231_loss: 0.4685 - val_dense_232_loss: 0.4685 - val_dense_233_loss: 2.2772 - val_dense_234_loss: 2.3212 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1562 - val_dense_234_acc: 0.0938\n",
            "Epoch 4/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4833 - dense_231_loss: 0.4283 - dense_232_loss: 0.4275 - dense_233_loss: 2.3067 - dense_234_loss: 2.3208 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1570 - dense_234_acc: 0.1130 - val_loss: 5.6043 - val_dense_231_loss: 0.4700 - val_dense_232_loss: 0.4843 - val_dense_233_loss: 2.2647 - val_dense_234_loss: 2.3853 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.0500\n",
            "Epoch 5/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4827 - dense_231_loss: 0.4271 - dense_232_loss: 0.4289 - dense_233_loss: 2.2983 - dense_234_loss: 2.3284 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1429 - dense_234_acc: 0.0879 - val_loss: 5.5524 - val_dense_231_loss: 0.4604 - val_dense_232_loss: 0.4612 - val_dense_233_loss: 2.2854 - val_dense_234_loss: 2.3454 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.0938 - val_dense_234_acc: 0.0938\n",
            "Epoch 6/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4560 - dense_231_loss: 0.4165 - dense_232_loss: 0.4264 - dense_233_loss: 2.2999 - dense_234_loss: 2.3132 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1319 - dense_234_acc: 0.1005 - val_loss: 5.5700 - val_dense_231_loss: 0.4525 - val_dense_232_loss: 0.4537 - val_dense_233_loss: 2.2731 - val_dense_234_loss: 2.3908 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1250\n",
            "Epoch 7/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4566 - dense_231_loss: 0.4189 - dense_232_loss: 0.4237 - dense_233_loss: 2.2947 - dense_234_loss: 2.3193 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1334 - dense_234_acc: 0.1209 - val_loss: 5.5047 - val_dense_231_loss: 0.4593 - val_dense_232_loss: 0.4607 - val_dense_233_loss: 2.2492 - val_dense_234_loss: 2.3354 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.0813\n",
            "Epoch 8/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4585 - dense_231_loss: 0.4223 - dense_232_loss: 0.4198 - dense_233_loss: 2.2937 - dense_234_loss: 2.3226 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1523 - dense_234_acc: 0.0958 - val_loss: 5.5211 - val_dense_231_loss: 0.4574 - val_dense_232_loss: 0.4568 - val_dense_233_loss: 2.2667 - val_dense_234_loss: 2.3402 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.0938\n",
            "Epoch 9/100\n",
            "637/637 [==============================] - 3s 4ms/step - loss: 5.4244 - dense_231_loss: 0.4072 - dense_232_loss: 0.4106 - dense_233_loss: 2.2967 - dense_234_loss: 2.3098 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1554 - dense_234_acc: 0.1036 - val_loss: 5.5253 - val_dense_231_loss: 0.4519 - val_dense_232_loss: 0.4518 - val_dense_233_loss: 2.2608 - val_dense_234_loss: 2.3608 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1187\n",
            "Epoch 10/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4297 - dense_231_loss: 0.4054 - dense_232_loss: 0.4074 - dense_233_loss: 2.2874 - dense_234_loss: 2.3294 - dense_231_acc: 0.8524 - dense_232_acc: 0.8524 - dense_233_acc: 0.1554 - dense_234_acc: 0.0926 - val_loss: 5.5787 - val_dense_231_loss: 0.4753 - val_dense_232_loss: 0.4712 - val_dense_233_loss: 2.3070 - val_dense_234_loss: 2.3252 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.0938 - val_dense_234_acc: 0.1125\n",
            "Epoch 11/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3445 - dense_231_loss: 0.3811 - dense_232_loss: 0.3743 - dense_233_loss: 2.2737 - dense_234_loss: 2.3154 - dense_231_acc: 0.8524 - dense_232_acc: 0.8556 - dense_233_acc: 0.1209 - dense_234_acc: 0.1036 - val_loss: 5.4848 - val_dense_231_loss: 0.4305 - val_dense_232_loss: 0.4399 - val_dense_233_loss: 2.2506 - val_dense_234_loss: 2.3638 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1187\n",
            "Epoch 12/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3416 - dense_231_loss: 0.3812 - dense_232_loss: 0.3773 - dense_233_loss: 2.2721 - dense_234_loss: 2.3110 - dense_231_acc: 0.8540 - dense_232_acc: 0.8556 - dense_233_acc: 0.1617 - dense_234_acc: 0.1287 - val_loss: 5.4374 - val_dense_231_loss: 0.4345 - val_dense_232_loss: 0.4305 - val_dense_233_loss: 2.2331 - val_dense_234_loss: 2.3392 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1250\n",
            "Epoch 13/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3583 - dense_231_loss: 0.3874 - dense_232_loss: 0.3916 - dense_233_loss: 2.2723 - dense_234_loss: 2.3069 - dense_231_acc: 0.8556 - dense_232_acc: 0.8571 - dense_233_acc: 0.1507 - dense_234_acc: 0.1366 - val_loss: 5.3951 - val_dense_231_loss: 0.4297 - val_dense_232_loss: 0.4223 - val_dense_233_loss: 2.2387 - val_dense_234_loss: 2.3044 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1250\n",
            "Epoch 14/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3682 - dense_231_loss: 0.3953 - dense_232_loss: 0.3944 - dense_233_loss: 2.2716 - dense_234_loss: 2.3068 - dense_231_acc: 0.8509 - dense_232_acc: 0.8493 - dense_233_acc: 0.1570 - dense_234_acc: 0.0958 - val_loss: 5.3576 - val_dense_231_loss: 0.4203 - val_dense_232_loss: 0.4057 - val_dense_233_loss: 2.2127 - val_dense_234_loss: 2.3190 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1313\n",
            "Epoch 15/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.4054 - dense_231_loss: 0.4212 - dense_232_loss: 0.4165 - dense_233_loss: 2.2683 - dense_234_loss: 2.2995 - dense_231_acc: 0.8477 - dense_232_acc: 0.8477 - dense_233_acc: 0.1476 - dense_234_acc: 0.1193 - val_loss: 5.4410 - val_dense_231_loss: 0.4144 - val_dense_232_loss: 0.4092 - val_dense_233_loss: 2.2654 - val_dense_234_loss: 2.3519 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2000 - val_dense_234_acc: 0.1062\n",
            "Epoch 16/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3471 - dense_231_loss: 0.3893 - dense_232_loss: 0.3903 - dense_233_loss: 2.2587 - dense_234_loss: 2.3088 - dense_231_acc: 0.8540 - dense_232_acc: 0.8524 - dense_233_acc: 0.1444 - dense_234_acc: 0.1272 - val_loss: 5.3318 - val_dense_231_loss: 0.3973 - val_dense_232_loss: 0.3923 - val_dense_233_loss: 2.2214 - val_dense_234_loss: 2.3209 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2000 - val_dense_234_acc: 0.0938\n",
            "Epoch 17/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3539 - dense_231_loss: 0.3885 - dense_232_loss: 0.3870 - dense_233_loss: 2.2758 - dense_234_loss: 2.3026 - dense_231_acc: 0.8493 - dense_232_acc: 0.8509 - dense_233_acc: 0.1491 - dense_234_acc: 0.1020 - val_loss: 5.3352 - val_dense_231_loss: 0.4057 - val_dense_232_loss: 0.3947 - val_dense_233_loss: 2.2126 - val_dense_234_loss: 2.3222 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1812 - val_dense_234_acc: 0.0813\n",
            "Epoch 18/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.3045 - dense_231_loss: 0.3781 - dense_232_loss: 0.3830 - dense_233_loss: 2.2526 - dense_234_loss: 2.2909 - dense_231_acc: 0.8524 - dense_232_acc: 0.8493 - dense_233_acc: 0.1664 - dense_234_acc: 0.1366 - val_loss: 5.2851 - val_dense_231_loss: 0.3946 - val_dense_232_loss: 0.3892 - val_dense_233_loss: 2.2034 - val_dense_234_loss: 2.2980 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1875 - val_dense_234_acc: 0.1062\n",
            "Epoch 19/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2893 - dense_231_loss: 0.3805 - dense_232_loss: 0.3774 - dense_233_loss: 2.2401 - dense_234_loss: 2.2913 - dense_231_acc: 0.8477 - dense_232_acc: 0.8493 - dense_233_acc: 0.1900 - dense_234_acc: 0.1444 - val_loss: 5.2229 - val_dense_231_loss: 0.3658 - val_dense_232_loss: 0.3678 - val_dense_233_loss: 2.1910 - val_dense_234_loss: 2.2983 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1812 - val_dense_234_acc: 0.1000\n",
            "Epoch 20/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2592 - dense_231_loss: 0.3686 - dense_232_loss: 0.3631 - dense_233_loss: 2.2456 - dense_234_loss: 2.2819 - dense_231_acc: 0.8587 - dense_232_acc: 0.8587 - dense_233_acc: 0.1695 - dense_234_acc: 0.1554 - val_loss: 5.2498 - val_dense_231_loss: 0.3825 - val_dense_232_loss: 0.3734 - val_dense_233_loss: 2.2084 - val_dense_234_loss: 2.2854 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2000 - val_dense_234_acc: 0.1250\n",
            "Epoch 21/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2062 - dense_231_loss: 0.3565 - dense_232_loss: 0.3507 - dense_233_loss: 2.2414 - dense_234_loss: 2.2576 - dense_231_acc: 0.8603 - dense_232_acc: 0.8619 - dense_233_acc: 0.1633 - dense_234_acc: 0.1554 - val_loss: 5.2263 - val_dense_231_loss: 0.3699 - val_dense_232_loss: 0.3787 - val_dense_233_loss: 2.1985 - val_dense_234_loss: 2.2792 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2188 - val_dense_234_acc: 0.1125\n",
            "Epoch 22/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2619 - dense_231_loss: 0.3650 - dense_232_loss: 0.3635 - dense_233_loss: 2.2420 - dense_234_loss: 2.2913 - dense_231_acc: 0.8603 - dense_232_acc: 0.8619 - dense_233_acc: 0.1915 - dense_234_acc: 0.1319 - val_loss: 5.2146 - val_dense_231_loss: 0.3719 - val_dense_232_loss: 0.3657 - val_dense_233_loss: 2.1839 - val_dense_234_loss: 2.2931 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1812 - val_dense_234_acc: 0.1250\n",
            "Epoch 23/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2309 - dense_231_loss: 0.3628 - dense_232_loss: 0.3604 - dense_233_loss: 2.2117 - dense_234_loss: 2.2960 - dense_231_acc: 0.8634 - dense_232_acc: 0.8587 - dense_233_acc: 0.1931 - dense_234_acc: 0.1334 - val_loss: 5.1743 - val_dense_231_loss: 0.3456 - val_dense_232_loss: 0.3529 - val_dense_233_loss: 2.1928 - val_dense_234_loss: 2.2830 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1688 - val_dense_234_acc: 0.1250\n",
            "Epoch 24/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1562 - dense_231_loss: 0.3415 - dense_232_loss: 0.3374 - dense_233_loss: 2.1997 - dense_234_loss: 2.2777 - dense_231_acc: 0.8603 - dense_232_acc: 0.8587 - dense_233_acc: 0.2088 - dense_234_acc: 0.1570 - val_loss: 5.0864 - val_dense_231_loss: 0.3349 - val_dense_232_loss: 0.3200 - val_dense_233_loss: 2.1385 - val_dense_234_loss: 2.2930 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.2437 - val_dense_234_acc: 0.1125\n",
            "Epoch 25/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1978 - dense_231_loss: 0.3525 - dense_232_loss: 0.3532 - dense_233_loss: 2.2191 - dense_234_loss: 2.2730 - dense_231_acc: 0.8509 - dense_232_acc: 0.8556 - dense_233_acc: 0.1931 - dense_234_acc: 0.1507 - val_loss: 5.1176 - val_dense_231_loss: 0.3364 - val_dense_232_loss: 0.3387 - val_dense_233_loss: 2.1623 - val_dense_234_loss: 2.2802 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1750 - val_dense_234_acc: 0.1125\n",
            "Epoch 26/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.2036 - dense_231_loss: 0.3562 - dense_232_loss: 0.3514 - dense_233_loss: 2.2192 - dense_234_loss: 2.2768 - dense_231_acc: 0.8524 - dense_232_acc: 0.8509 - dense_233_acc: 0.1915 - dense_234_acc: 0.1633 - val_loss: 5.1199 - val_dense_231_loss: 0.3312 - val_dense_232_loss: 0.3314 - val_dense_233_loss: 2.1811 - val_dense_234_loss: 2.2762 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1875 - val_dense_234_acc: 0.1125\n",
            "Epoch 27/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1453 - dense_231_loss: 0.3441 - dense_232_loss: 0.3347 - dense_233_loss: 2.2002 - dense_234_loss: 2.2663 - dense_231_acc: 0.8634 - dense_232_acc: 0.8713 - dense_233_acc: 0.1947 - dense_234_acc: 0.1554 - val_loss: 5.0571 - val_dense_231_loss: 0.3320 - val_dense_232_loss: 0.3240 - val_dense_233_loss: 2.1460 - val_dense_234_loss: 2.2550 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.1812 - val_dense_234_acc: 0.1437\n",
            "Epoch 28/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1397 - dense_231_loss: 0.3314 - dense_232_loss: 0.3297 - dense_233_loss: 2.2032 - dense_234_loss: 2.2755 - dense_231_acc: 0.8634 - dense_232_acc: 0.8681 - dense_233_acc: 0.1837 - dense_234_acc: 0.1491 - val_loss: 5.1277 - val_dense_231_loss: 0.3392 - val_dense_232_loss: 0.3371 - val_dense_233_loss: 2.1464 - val_dense_234_loss: 2.3051 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1938 - val_dense_234_acc: 0.1875\n",
            "Epoch 29/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1217 - dense_231_loss: 0.3365 - dense_232_loss: 0.3351 - dense_233_loss: 2.2016 - dense_234_loss: 2.2485 - dense_231_acc: 0.8587 - dense_232_acc: 0.8619 - dense_233_acc: 0.1884 - dense_234_acc: 0.1554 - val_loss: 5.0890 - val_dense_231_loss: 0.3152 - val_dense_232_loss: 0.3197 - val_dense_233_loss: 2.1670 - val_dense_234_loss: 2.2872 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8375 - val_dense_233_acc: 0.1938 - val_dense_234_acc: 0.1750\n",
            "Epoch 30/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.1719 - dense_231_loss: 0.3399 - dense_232_loss: 0.3376 - dense_233_loss: 2.2261 - dense_234_loss: 2.2683 - dense_231_acc: 0.8587 - dense_232_acc: 0.8634 - dense_233_acc: 0.1758 - dense_234_acc: 0.1413 - val_loss: 5.0569 - val_dense_231_loss: 0.3132 - val_dense_232_loss: 0.3141 - val_dense_233_loss: 2.1568 - val_dense_234_loss: 2.2728 - val_dense_231_acc: 0.8375 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.1938 - val_dense_234_acc: 0.1688\n",
            "Epoch 31/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0933 - dense_231_loss: 0.3198 - dense_232_loss: 0.3204 - dense_233_loss: 2.1958 - dense_234_loss: 2.2574 - dense_231_acc: 0.8776 - dense_232_acc: 0.8728 - dense_233_acc: 0.2009 - dense_234_acc: 0.1774 - val_loss: 4.9847 - val_dense_231_loss: 0.2985 - val_dense_232_loss: 0.2971 - val_dense_233_loss: 2.1342 - val_dense_234_loss: 2.2549 - val_dense_231_acc: 0.8375 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.2375 - val_dense_234_acc: 0.1625\n",
            "Epoch 32/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0936 - dense_231_loss: 0.3287 - dense_232_loss: 0.3208 - dense_233_loss: 2.1779 - dense_234_loss: 2.2661 - dense_231_acc: 0.8728 - dense_232_acc: 0.8776 - dense_233_acc: 0.2072 - dense_234_acc: 0.1538 - val_loss: 5.0662 - val_dense_231_loss: 0.3198 - val_dense_232_loss: 0.3343 - val_dense_233_loss: 2.1496 - val_dense_234_loss: 2.2625 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.1812 - val_dense_234_acc: 0.1313\n",
            "Epoch 33/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0531 - dense_231_loss: 0.3188 - dense_232_loss: 0.3198 - dense_233_loss: 2.1677 - dense_234_loss: 2.2468 - dense_231_acc: 0.8791 - dense_232_acc: 0.8760 - dense_233_acc: 0.2182 - dense_234_acc: 0.1695 - val_loss: 5.0464 - val_dense_231_loss: 0.3096 - val_dense_232_loss: 0.3272 - val_dense_233_loss: 2.1447 - val_dense_234_loss: 2.2649 - val_dense_231_acc: 0.8375 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2188 - val_dense_234_acc: 0.1500\n",
            "Epoch 34/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0594 - dense_231_loss: 0.3240 - dense_232_loss: 0.3168 - dense_233_loss: 2.1633 - dense_234_loss: 2.2554 - dense_231_acc: 0.8713 - dense_232_acc: 0.8713 - dense_233_acc: 0.2166 - dense_234_acc: 0.1586 - val_loss: 4.9259 - val_dense_231_loss: 0.3038 - val_dense_232_loss: 0.3033 - val_dense_233_loss: 2.0813 - val_dense_234_loss: 2.2375 - val_dense_231_acc: 0.8438 - val_dense_232_acc: 0.8625 - val_dense_233_acc: 0.3063 - val_dense_234_acc: 0.1938\n",
            "Epoch 35/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0162 - dense_231_loss: 0.3273 - dense_232_loss: 0.3189 - dense_233_loss: 2.1470 - dense_234_loss: 2.2230 - dense_231_acc: 0.8728 - dense_232_acc: 0.8744 - dense_233_acc: 0.2402 - dense_234_acc: 0.2135 - val_loss: 5.0282 - val_dense_231_loss: 0.3194 - val_dense_232_loss: 0.3333 - val_dense_233_loss: 2.1289 - val_dense_234_loss: 2.2466 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8375 - val_dense_233_acc: 0.2437 - val_dense_234_acc: 0.1250\n",
            "Epoch 36/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 5.0545 - dense_231_loss: 0.3348 - dense_232_loss: 0.3319 - dense_233_loss: 2.1536 - dense_234_loss: 2.2343 - dense_231_acc: 0.8697 - dense_232_acc: 0.8603 - dense_233_acc: 0.2339 - dense_234_acc: 0.1837 - val_loss: 4.8758 - val_dense_231_loss: 0.3050 - val_dense_232_loss: 0.3080 - val_dense_233_loss: 2.0544 - val_dense_234_loss: 2.2084 - val_dense_231_acc: 0.8438 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.2750 - val_dense_234_acc: 0.2313\n",
            "Epoch 37/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.9597 - dense_231_loss: 0.3239 - dense_232_loss: 0.3213 - dense_233_loss: 2.1260 - dense_234_loss: 2.1885 - dense_231_acc: 0.8744 - dense_232_acc: 0.8681 - dense_233_acc: 0.2308 - dense_234_acc: 0.2151 - val_loss: 4.8643 - val_dense_231_loss: 0.3057 - val_dense_232_loss: 0.3088 - val_dense_233_loss: 2.0432 - val_dense_234_loss: 2.2065 - val_dense_231_acc: 0.8812 - val_dense_232_acc: 0.8688 - val_dense_233_acc: 0.2375 - val_dense_234_acc: 0.1688\n",
            "Epoch 38/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.9921 - dense_231_loss: 0.3288 - dense_232_loss: 0.3286 - dense_233_loss: 2.1203 - dense_234_loss: 2.2144 - dense_231_acc: 0.8681 - dense_232_acc: 0.8634 - dense_233_acc: 0.2465 - dense_234_acc: 0.1947 - val_loss: 4.9247 - val_dense_231_loss: 0.3384 - val_dense_232_loss: 0.3620 - val_dense_233_loss: 2.0525 - val_dense_234_loss: 2.1718 - val_dense_231_acc: 0.8313 - val_dense_232_acc: 0.8313 - val_dense_233_acc: 0.2562 - val_dense_234_acc: 0.2812\n",
            "Epoch 39/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.8965 - dense_231_loss: 0.3228 - dense_232_loss: 0.3203 - dense_233_loss: 2.0712 - dense_234_loss: 2.1822 - dense_231_acc: 0.8760 - dense_232_acc: 0.8760 - dense_233_acc: 0.2637 - dense_234_acc: 0.2245 - val_loss: 4.6752 - val_dense_231_loss: 0.3134 - val_dense_232_loss: 0.3175 - val_dense_233_loss: 1.9560 - val_dense_234_loss: 2.0883 - val_dense_231_acc: 0.8438 - val_dense_232_acc: 0.8562 - val_dense_233_acc: 0.2938 - val_dense_234_acc: 0.2687\n",
            "Epoch 40/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.9034 - dense_231_loss: 0.3198 - dense_232_loss: 0.3209 - dense_233_loss: 2.0820 - dense_234_loss: 2.1807 - dense_231_acc: 0.8838 - dense_232_acc: 0.8744 - dense_233_acc: 0.2716 - dense_234_acc: 0.2119 - val_loss: 4.6925 - val_dense_231_loss: 0.3048 - val_dense_232_loss: 0.3077 - val_dense_233_loss: 1.9554 - val_dense_234_loss: 2.1245 - val_dense_231_acc: 0.8438 - val_dense_232_acc: 0.8562 - val_dense_233_acc: 0.3375 - val_dense_234_acc: 0.2875\n",
            "Epoch 41/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.9437 - dense_231_loss: 0.3360 - dense_232_loss: 0.3345 - dense_233_loss: 2.0980 - dense_234_loss: 2.1752 - dense_231_acc: 0.8587 - dense_232_acc: 0.8650 - dense_233_acc: 0.2622 - dense_234_acc: 0.2104 - val_loss: 4.6853 - val_dense_231_loss: 0.3033 - val_dense_232_loss: 0.3132 - val_dense_233_loss: 1.9171 - val_dense_234_loss: 2.1517 - val_dense_231_acc: 0.8438 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.3688 - val_dense_234_acc: 0.2437\n",
            "Epoch 42/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.8389 - dense_231_loss: 0.3327 - dense_232_loss: 0.3306 - dense_233_loss: 2.0555 - dense_234_loss: 2.1202 - dense_231_acc: 0.8713 - dense_232_acc: 0.8634 - dense_233_acc: 0.2606 - dense_234_acc: 0.2559 - val_loss: 4.4848 - val_dense_231_loss: 0.2829 - val_dense_232_loss: 0.2751 - val_dense_233_loss: 1.8837 - val_dense_234_loss: 2.0431 - val_dense_231_acc: 0.8812 - val_dense_232_acc: 0.8875 - val_dense_233_acc: 0.3625 - val_dense_234_acc: 0.2687\n",
            "Epoch 43/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.7703 - dense_231_loss: 0.2992 - dense_232_loss: 0.2948 - dense_233_loss: 2.0434 - dense_234_loss: 2.1328 - dense_231_acc: 0.8870 - dense_232_acc: 0.8870 - dense_233_acc: 0.2841 - dense_234_acc: 0.2433 - val_loss: 4.6857 - val_dense_231_loss: 0.2969 - val_dense_232_loss: 0.2920 - val_dense_233_loss: 1.9845 - val_dense_234_loss: 2.1122 - val_dense_231_acc: 0.8688 - val_dense_232_acc: 0.8875 - val_dense_233_acc: 0.2812 - val_dense_234_acc: 0.2313\n",
            "Epoch 44/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.7864 - dense_231_loss: 0.3033 - dense_232_loss: 0.3007 - dense_233_loss: 2.0194 - dense_234_loss: 2.1630 - dense_231_acc: 0.8838 - dense_232_acc: 0.8885 - dense_233_acc: 0.2841 - dense_234_acc: 0.2402 - val_loss: 4.6411 - val_dense_231_loss: 0.2929 - val_dense_232_loss: 0.2922 - val_dense_233_loss: 1.9672 - val_dense_234_loss: 2.0888 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.2500 - val_dense_234_acc: 0.3000\n",
            "Epoch 45/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6873 - dense_231_loss: 0.2818 - dense_232_loss: 0.2808 - dense_233_loss: 2.0208 - dense_234_loss: 2.1040 - dense_231_acc: 0.8932 - dense_232_acc: 0.8948 - dense_233_acc: 0.3077 - dense_234_acc: 0.2559 - val_loss: 4.5171 - val_dense_231_loss: 0.2872 - val_dense_232_loss: 0.2850 - val_dense_233_loss: 1.8753 - val_dense_234_loss: 2.0696 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.3750 - val_dense_234_acc: 0.2437\n",
            "Epoch 46/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.8190 - dense_231_loss: 0.3291 - dense_232_loss: 0.3288 - dense_233_loss: 2.0224 - dense_234_loss: 2.1388 - dense_231_acc: 0.8744 - dense_232_acc: 0.8776 - dense_233_acc: 0.3046 - dense_234_acc: 0.2245 - val_loss: 4.6115 - val_dense_231_loss: 0.3118 - val_dense_232_loss: 0.3116 - val_dense_233_loss: 1.9366 - val_dense_234_loss: 2.0515 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.3063 - val_dense_234_acc: 0.3187\n",
            "Epoch 47/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6923 - dense_231_loss: 0.2858 - dense_232_loss: 0.2819 - dense_233_loss: 2.0293 - dense_234_loss: 2.0953 - dense_231_acc: 0.8980 - dense_232_acc: 0.8948 - dense_233_acc: 0.2763 - dense_234_acc: 0.2684 - val_loss: 4.3689 - val_dense_231_loss: 0.2810 - val_dense_232_loss: 0.2640 - val_dense_233_loss: 1.8632 - val_dense_234_loss: 1.9607 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.3125 - val_dense_234_acc: 0.4000\n",
            "Epoch 48/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6902 - dense_231_loss: 0.3067 - dense_232_loss: 0.2997 - dense_233_loss: 2.0054 - dense_234_loss: 2.0785 - dense_231_acc: 0.8776 - dense_232_acc: 0.8744 - dense_233_acc: 0.2983 - dense_234_acc: 0.3061 - val_loss: 4.4076 - val_dense_231_loss: 0.2901 - val_dense_232_loss: 0.2881 - val_dense_233_loss: 1.8396 - val_dense_234_loss: 1.9898 - val_dense_231_acc: 0.8812 - val_dense_232_acc: 0.8812 - val_dense_233_acc: 0.3812 - val_dense_234_acc: 0.3375\n",
            "Epoch 49/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6208 - dense_231_loss: 0.2964 - dense_232_loss: 0.2871 - dense_233_loss: 1.9816 - dense_234_loss: 2.0556 - dense_231_acc: 0.8807 - dense_232_acc: 0.8870 - dense_233_acc: 0.3312 - dense_234_acc: 0.2904 - val_loss: 4.3787 - val_dense_231_loss: 0.3001 - val_dense_232_loss: 0.2851 - val_dense_233_loss: 1.8442 - val_dense_234_loss: 1.9494 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8875 - val_dense_233_acc: 0.3375 - val_dense_234_acc: 0.3625\n",
            "Epoch 50/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6160 - dense_231_loss: 0.2927 - dense_232_loss: 0.2921 - dense_233_loss: 1.9976 - dense_234_loss: 2.0336 - dense_231_acc: 0.8791 - dense_232_acc: 0.8838 - dense_233_acc: 0.2763 - dense_234_acc: 0.3218 - val_loss: 4.5848 - val_dense_231_loss: 0.3253 - val_dense_232_loss: 0.3444 - val_dense_233_loss: 1.8463 - val_dense_234_loss: 2.0687 - val_dense_231_acc: 0.8500 - val_dense_232_acc: 0.8438 - val_dense_233_acc: 0.3750 - val_dense_234_acc: 0.3438\n",
            "Epoch 51/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6273 - dense_231_loss: 0.3033 - dense_232_loss: 0.3054 - dense_233_loss: 1.9759 - dense_234_loss: 2.0428 - dense_231_acc: 0.8776 - dense_232_acc: 0.8776 - dense_233_acc: 0.3061 - dense_234_acc: 0.2951 - val_loss: 4.2672 - val_dense_231_loss: 0.2945 - val_dense_232_loss: 0.2823 - val_dense_233_loss: 1.7984 - val_dense_234_loss: 1.8920 - val_dense_231_acc: 0.8625 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.4188\n",
            "Epoch 52/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.5626 - dense_231_loss: 0.2830 - dense_232_loss: 0.2785 - dense_233_loss: 1.9572 - dense_234_loss: 2.0439 - dense_231_acc: 0.8823 - dense_232_acc: 0.8807 - dense_233_acc: 0.3359 - dense_234_acc: 0.2936 - val_loss: 4.1001 - val_dense_231_loss: 0.2735 - val_dense_232_loss: 0.2636 - val_dense_233_loss: 1.7297 - val_dense_234_loss: 1.8334 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4188 - val_dense_234_acc: 0.4250\n",
            "Epoch 53/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.6100 - dense_231_loss: 0.3077 - dense_232_loss: 0.3069 - dense_233_loss: 1.9649 - dense_234_loss: 2.0305 - dense_231_acc: 0.8854 - dense_232_acc: 0.8870 - dense_233_acc: 0.3265 - dense_234_acc: 0.3077 - val_loss: 4.1316 - val_dense_231_loss: 0.2867 - val_dense_232_loss: 0.2735 - val_dense_233_loss: 1.7616 - val_dense_234_loss: 1.8098 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.3375 - val_dense_234_acc: 0.4000\n",
            "Epoch 54/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.5319 - dense_231_loss: 0.2994 - dense_232_loss: 0.2963 - dense_233_loss: 1.9218 - dense_234_loss: 2.0144 - dense_231_acc: 0.8901 - dense_232_acc: 0.8885 - dense_233_acc: 0.3391 - dense_234_acc: 0.3187 - val_loss: 4.0776 - val_dense_231_loss: 0.2837 - val_dense_232_loss: 0.2699 - val_dense_233_loss: 1.6998 - val_dense_234_loss: 1.8242 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4125 - val_dense_234_acc: 0.3625\n",
            "Epoch 55/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.5318 - dense_231_loss: 0.3052 - dense_232_loss: 0.3031 - dense_233_loss: 1.8860 - dense_234_loss: 2.0375 - dense_231_acc: 0.8838 - dense_232_acc: 0.8870 - dense_233_acc: 0.3391 - dense_234_acc: 0.2951 - val_loss: 3.9812 - val_dense_231_loss: 0.2791 - val_dense_232_loss: 0.2614 - val_dense_233_loss: 1.6805 - val_dense_234_loss: 1.7600 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4062 - val_dense_234_acc: 0.4313\n",
            "Epoch 56/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.4886 - dense_231_loss: 0.2947 - dense_232_loss: 0.2906 - dense_233_loss: 1.8858 - dense_234_loss: 2.0175 - dense_231_acc: 0.8838 - dense_232_acc: 0.8854 - dense_233_acc: 0.3375 - dense_234_acc: 0.2998 - val_loss: 4.0266 - val_dense_231_loss: 0.2801 - val_dense_232_loss: 0.2662 - val_dense_233_loss: 1.6924 - val_dense_234_loss: 1.7879 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4375 - val_dense_234_acc: 0.4375\n",
            "Epoch 57/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.4398 - dense_231_loss: 0.2786 - dense_232_loss: 0.2783 - dense_233_loss: 1.8667 - dense_234_loss: 2.0162 - dense_231_acc: 0.8980 - dense_232_acc: 0.8980 - dense_233_acc: 0.3611 - dense_234_acc: 0.3030 - val_loss: 4.0602 - val_dense_231_loss: 0.2774 - val_dense_232_loss: 0.2638 - val_dense_233_loss: 1.7292 - val_dense_234_loss: 1.7899 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4062 - val_dense_234_acc: 0.4375\n",
            "Epoch 58/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.4840 - dense_231_loss: 0.2869 - dense_232_loss: 0.2814 - dense_233_loss: 1.9500 - dense_234_loss: 1.9656 - dense_231_acc: 0.8980 - dense_232_acc: 0.8995 - dense_233_acc: 0.3344 - dense_234_acc: 0.3375 - val_loss: 4.0257 - val_dense_231_loss: 0.2865 - val_dense_232_loss: 0.2843 - val_dense_233_loss: 1.6554 - val_dense_234_loss: 1.7996 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4562 - val_dense_234_acc: 0.5000\n",
            "Epoch 59/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.4711 - dense_231_loss: 0.3052 - dense_232_loss: 0.2987 - dense_233_loss: 1.8889 - dense_234_loss: 1.9783 - dense_231_acc: 0.8870 - dense_232_acc: 0.8885 - dense_233_acc: 0.3579 - dense_234_acc: 0.3265 - val_loss: 3.9036 - val_dense_231_loss: 0.2930 - val_dense_232_loss: 0.2894 - val_dense_233_loss: 1.6224 - val_dense_234_loss: 1.6988 - val_dense_231_acc: 0.8812 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4125 - val_dense_234_acc: 0.4813\n",
            "Epoch 60/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.4160 - dense_231_loss: 0.2885 - dense_232_loss: 0.2892 - dense_233_loss: 1.8544 - dense_234_loss: 1.9839 - dense_231_acc: 0.8901 - dense_232_acc: 0.8948 - dense_233_acc: 0.3689 - dense_234_acc: 0.3171 - val_loss: 3.8707 - val_dense_231_loss: 0.2734 - val_dense_232_loss: 0.2707 - val_dense_233_loss: 1.6023 - val_dense_234_loss: 1.7243 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4437 - val_dense_234_acc: 0.4562\n",
            "Epoch 61/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.3826 - dense_231_loss: 0.2859 - dense_232_loss: 0.2821 - dense_233_loss: 1.8274 - dense_234_loss: 1.9873 - dense_231_acc: 0.8932 - dense_232_acc: 0.8980 - dense_233_acc: 0.3783 - dense_234_acc: 0.3297 - val_loss: 3.9838 - val_dense_231_loss: 0.3013 - val_dense_232_loss: 0.2993 - val_dense_233_loss: 1.6059 - val_dense_234_loss: 1.7774 - val_dense_231_acc: 0.8812 - val_dense_232_acc: 0.8812 - val_dense_233_acc: 0.4750 - val_dense_234_acc: 0.4750\n",
            "Epoch 62/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2733 - dense_231_loss: 0.2722 - dense_232_loss: 0.2708 - dense_233_loss: 1.7937 - dense_234_loss: 1.9367 - dense_231_acc: 0.8870 - dense_232_acc: 0.8901 - dense_233_acc: 0.3799 - dense_234_acc: 0.3642 - val_loss: 3.8272 - val_dense_231_loss: 0.2711 - val_dense_232_loss: 0.2600 - val_dense_233_loss: 1.5941 - val_dense_234_loss: 1.7020 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.8875 - val_dense_233_acc: 0.4375 - val_dense_234_acc: 0.4188\n",
            "Epoch 63/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2753 - dense_231_loss: 0.2717 - dense_232_loss: 0.2649 - dense_233_loss: 1.8086 - dense_234_loss: 1.9301 - dense_231_acc: 0.9042 - dense_232_acc: 0.8995 - dense_233_acc: 0.3673 - dense_234_acc: 0.3297 - val_loss: 3.8006 - val_dense_231_loss: 0.2781 - val_dense_232_loss: 0.2769 - val_dense_233_loss: 1.5877 - val_dense_234_loss: 1.6578 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4625 - val_dense_234_acc: 0.4688\n",
            "Epoch 64/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.3113 - dense_231_loss: 0.2844 - dense_232_loss: 0.2776 - dense_233_loss: 1.8126 - dense_234_loss: 1.9367 - dense_231_acc: 0.8823 - dense_232_acc: 0.8870 - dense_233_acc: 0.3878 - dense_234_acc: 0.3281 - val_loss: 3.7901 - val_dense_231_loss: 0.2726 - val_dense_232_loss: 0.2614 - val_dense_233_loss: 1.5860 - val_dense_234_loss: 1.6701 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.4938\n",
            "Epoch 65/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.1979 - dense_231_loss: 0.2588 - dense_232_loss: 0.2613 - dense_233_loss: 1.8100 - dense_234_loss: 1.8678 - dense_231_acc: 0.8980 - dense_232_acc: 0.8995 - dense_233_acc: 0.3830 - dense_234_acc: 0.3768 - val_loss: 3.7979 - val_dense_231_loss: 0.2815 - val_dense_232_loss: 0.2732 - val_dense_233_loss: 1.6128 - val_dense_234_loss: 1.6304 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4500 - val_dense_234_acc: 0.5000\n",
            "Epoch 66/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2483 - dense_231_loss: 0.2596 - dense_232_loss: 0.2590 - dense_233_loss: 1.7873 - dense_234_loss: 1.9425 - dense_231_acc: 0.9027 - dense_232_acc: 0.9058 - dense_233_acc: 0.4082 - dense_234_acc: 0.3454 - val_loss: 3.7325 - val_dense_231_loss: 0.2801 - val_dense_232_loss: 0.2745 - val_dense_233_loss: 1.5752 - val_dense_234_loss: 1.6027 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4688 - val_dense_234_acc: 0.5687\n",
            "Epoch 67/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.1766 - dense_231_loss: 0.2647 - dense_232_loss: 0.2620 - dense_233_loss: 1.7479 - dense_234_loss: 1.9021 - dense_231_acc: 0.8964 - dense_232_acc: 0.9027 - dense_233_acc: 0.3940 - dense_234_acc: 0.3469 - val_loss: 3.7504 - val_dense_231_loss: 0.2756 - val_dense_232_loss: 0.2714 - val_dense_233_loss: 1.5619 - val_dense_234_loss: 1.6415 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4562 - val_dense_234_acc: 0.5000\n",
            "Epoch 68/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2017 - dense_231_loss: 0.2637 - dense_232_loss: 0.2634 - dense_233_loss: 1.7734 - dense_234_loss: 1.9012 - dense_231_acc: 0.8980 - dense_232_acc: 0.9011 - dense_233_acc: 0.3940 - dense_234_acc: 0.3422 - val_loss: 3.7413 - val_dense_231_loss: 0.2777 - val_dense_232_loss: 0.2725 - val_dense_233_loss: 1.5740 - val_dense_234_loss: 1.6171 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4875 - val_dense_234_acc: 0.4875\n",
            "Epoch 69/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2390 - dense_231_loss: 0.2712 - dense_232_loss: 0.2659 - dense_233_loss: 1.7963 - dense_234_loss: 1.9056 - dense_231_acc: 0.8901 - dense_232_acc: 0.8917 - dense_233_acc: 0.3878 - dense_234_acc: 0.3532 - val_loss: 3.7704 - val_dense_231_loss: 0.2896 - val_dense_232_loss: 0.2870 - val_dense_233_loss: 1.5863 - val_dense_234_loss: 1.6076 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.8812 - val_dense_233_acc: 0.3937 - val_dense_234_acc: 0.4750\n",
            "Epoch 70/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.2322 - dense_231_loss: 0.2716 - dense_232_loss: 0.2611 - dense_233_loss: 1.8387 - dense_234_loss: 1.8609 - dense_231_acc: 0.8870 - dense_232_acc: 0.8964 - dense_233_acc: 0.3846 - dense_234_acc: 0.3642 - val_loss: 3.6343 - val_dense_231_loss: 0.2675 - val_dense_232_loss: 0.2613 - val_dense_233_loss: 1.5555 - val_dense_234_loss: 1.5500 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4625 - val_dense_234_acc: 0.5188\n",
            "Epoch 71/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.0684 - dense_231_loss: 0.2414 - dense_232_loss: 0.2420 - dense_233_loss: 1.7548 - dense_234_loss: 1.8302 - dense_231_acc: 0.9074 - dense_232_acc: 0.9074 - dense_233_acc: 0.3752 - dense_234_acc: 0.3689 - val_loss: 3.7490 - val_dense_231_loss: 0.2855 - val_dense_232_loss: 0.2788 - val_dense_233_loss: 1.5496 - val_dense_234_loss: 1.6350 - val_dense_231_acc: 0.8875 - val_dense_232_acc: 0.8875 - val_dense_233_acc: 0.4188 - val_dense_234_acc: 0.4375\n",
            "Epoch 72/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.1150 - dense_231_loss: 0.2593 - dense_232_loss: 0.2565 - dense_233_loss: 1.7234 - dense_234_loss: 1.8757 - dense_231_acc: 0.9042 - dense_232_acc: 0.9027 - dense_233_acc: 0.4301 - dense_234_acc: 0.3454 - val_loss: 3.6800 - val_dense_231_loss: 0.2712 - val_dense_232_loss: 0.2662 - val_dense_233_loss: 1.5339 - val_dense_234_loss: 1.6087 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4813 - val_dense_234_acc: 0.5000\n",
            "Epoch 73/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.0976 - dense_231_loss: 0.2588 - dense_232_loss: 0.2569 - dense_233_loss: 1.7430 - dense_234_loss: 1.8390 - dense_231_acc: 0.8917 - dense_232_acc: 0.8917 - dense_233_acc: 0.4097 - dense_234_acc: 0.3689 - val_loss: 3.6163 - val_dense_231_loss: 0.2573 - val_dense_232_loss: 0.2523 - val_dense_233_loss: 1.5085 - val_dense_234_loss: 1.5982 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4500 - val_dense_234_acc: 0.4313\n",
            "Epoch 74/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.1585 - dense_231_loss: 0.2485 - dense_232_loss: 0.2430 - dense_233_loss: 1.8029 - dense_234_loss: 1.8641 - dense_231_acc: 0.8932 - dense_232_acc: 0.9011 - dense_233_acc: 0.3783 - dense_234_acc: 0.3626 - val_loss: 3.5730 - val_dense_231_loss: 0.2542 - val_dense_232_loss: 0.2557 - val_dense_233_loss: 1.5471 - val_dense_234_loss: 1.5160 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4125 - val_dense_234_acc: 0.5000\n",
            "Epoch 75/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.0366 - dense_231_loss: 0.2625 - dense_232_loss: 0.2594 - dense_233_loss: 1.7258 - dense_234_loss: 1.7889 - dense_231_acc: 0.8980 - dense_232_acc: 0.8964 - dense_233_acc: 0.4082 - dense_234_acc: 0.3940 - val_loss: 3.7389 - val_dense_231_loss: 0.2548 - val_dense_232_loss: 0.2538 - val_dense_233_loss: 1.5064 - val_dense_234_loss: 1.7238 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4625 - val_dense_234_acc: 0.3937\n",
            "Epoch 76/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 4.0483 - dense_231_loss: 0.2567 - dense_232_loss: 0.2548 - dense_233_loss: 1.7062 - dense_234_loss: 1.8306 - dense_231_acc: 0.9042 - dense_232_acc: 0.8980 - dense_233_acc: 0.4176 - dense_234_acc: 0.3783 - val_loss: 3.6122 - val_dense_231_loss: 0.2601 - val_dense_232_loss: 0.2573 - val_dense_233_loss: 1.5423 - val_dense_234_loss: 1.5526 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4125 - val_dense_234_acc: 0.5062\n",
            "Epoch 77/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9880 - dense_231_loss: 0.2482 - dense_232_loss: 0.2459 - dense_233_loss: 1.7428 - dense_234_loss: 1.7511 - dense_231_acc: 0.8995 - dense_232_acc: 0.9074 - dense_233_acc: 0.4176 - dense_234_acc: 0.3862 - val_loss: 3.4567 - val_dense_231_loss: 0.2638 - val_dense_232_loss: 0.2619 - val_dense_233_loss: 1.4761 - val_dense_234_loss: 1.4548 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4188 - val_dense_234_acc: 0.5375\n",
            "Epoch 78/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9471 - dense_231_loss: 0.2462 - dense_232_loss: 0.2399 - dense_233_loss: 1.7221 - dense_234_loss: 1.7389 - dense_231_acc: 0.9089 - dense_232_acc: 0.9089 - dense_233_acc: 0.4082 - dense_234_acc: 0.4160 - val_loss: 3.5866 - val_dense_231_loss: 0.2708 - val_dense_232_loss: 0.2698 - val_dense_233_loss: 1.4826 - val_dense_234_loss: 1.5633 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.5000 - val_dense_234_acc: 0.4562\n",
            "Epoch 79/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9900 - dense_231_loss: 0.2535 - dense_232_loss: 0.2554 - dense_233_loss: 1.6679 - dense_234_loss: 1.8132 - dense_231_acc: 0.9089 - dense_232_acc: 0.9089 - dense_233_acc: 0.4427 - dense_234_acc: 0.3815 - val_loss: 3.4560 - val_dense_231_loss: 0.2516 - val_dense_232_loss: 0.2464 - val_dense_233_loss: 1.4761 - val_dense_234_loss: 1.4820 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.3750 - val_dense_234_acc: 0.5062\n",
            "Epoch 80/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9666 - dense_231_loss: 0.2519 - dense_232_loss: 0.2518 - dense_233_loss: 1.7361 - dense_234_loss: 1.7268 - dense_231_acc: 0.8995 - dense_232_acc: 0.8995 - dense_233_acc: 0.4019 - dense_234_acc: 0.4003 - val_loss: 3.5253 - val_dense_231_loss: 0.2564 - val_dense_232_loss: 0.2565 - val_dense_233_loss: 1.5414 - val_dense_234_loss: 1.4710 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4625 - val_dense_234_acc: 0.5375\n",
            "Epoch 81/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9475 - dense_231_loss: 0.2391 - dense_232_loss: 0.2344 - dense_233_loss: 1.6975 - dense_234_loss: 1.7766 - dense_231_acc: 0.9058 - dense_232_acc: 0.9058 - dense_233_acc: 0.4317 - dense_234_acc: 0.3705 - val_loss: 3.7135 - val_dense_231_loss: 0.2578 - val_dense_232_loss: 0.2589 - val_dense_233_loss: 1.5462 - val_dense_234_loss: 1.6506 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.4250\n",
            "Epoch 82/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9006 - dense_231_loss: 0.2393 - dense_232_loss: 0.2389 - dense_233_loss: 1.6365 - dense_234_loss: 1.7859 - dense_231_acc: 0.8964 - dense_232_acc: 0.9011 - dense_233_acc: 0.4505 - dense_234_acc: 0.3909 - val_loss: 3.4395 - val_dense_231_loss: 0.2490 - val_dense_232_loss: 0.2463 - val_dense_233_loss: 1.4949 - val_dense_234_loss: 1.4493 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4188 - val_dense_234_acc: 0.5250\n",
            "Epoch 83/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.9472 - dense_231_loss: 0.2571 - dense_232_loss: 0.2454 - dense_233_loss: 1.6809 - dense_234_loss: 1.7638 - dense_231_acc: 0.9058 - dense_232_acc: 0.9105 - dense_233_acc: 0.4254 - dense_234_acc: 0.3972 - val_loss: 3.5368 - val_dense_231_loss: 0.2783 - val_dense_232_loss: 0.2758 - val_dense_233_loss: 1.4951 - val_dense_234_loss: 1.4877 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4437 - val_dense_234_acc: 0.5250\n",
            "Epoch 84/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8712 - dense_231_loss: 0.2352 - dense_232_loss: 0.2289 - dense_233_loss: 1.7279 - dense_234_loss: 1.6792 - dense_231_acc: 0.9027 - dense_232_acc: 0.9074 - dense_233_acc: 0.4160 - dense_234_acc: 0.4411 - val_loss: 3.4779 - val_dense_231_loss: 0.2504 - val_dense_232_loss: 0.2472 - val_dense_233_loss: 1.4893 - val_dense_234_loss: 1.4910 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.5437\n",
            "Epoch 85/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8517 - dense_231_loss: 0.2239 - dense_232_loss: 0.2173 - dense_233_loss: 1.6367 - dense_234_loss: 1.7738 - dense_231_acc: 0.9137 - dense_232_acc: 0.9152 - dense_233_acc: 0.4254 - dense_234_acc: 0.3925 - val_loss: 3.4171 - val_dense_231_loss: 0.2523 - val_dense_232_loss: 0.2523 - val_dense_233_loss: 1.5055 - val_dense_234_loss: 1.4070 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.5938\n",
            "Epoch 86/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8010 - dense_231_loss: 0.2376 - dense_232_loss: 0.2328 - dense_233_loss: 1.6235 - dense_234_loss: 1.7071 - dense_231_acc: 0.9121 - dense_232_acc: 0.9121 - dense_233_acc: 0.4223 - dense_234_acc: 0.4286 - val_loss: 3.4737 - val_dense_231_loss: 0.2612 - val_dense_232_loss: 0.2643 - val_dense_233_loss: 1.5032 - val_dense_234_loss: 1.4450 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.4875\n",
            "Epoch 87/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.7800 - dense_231_loss: 0.2308 - dense_232_loss: 0.2354 - dense_233_loss: 1.6444 - dense_234_loss: 1.6694 - dense_231_acc: 0.9105 - dense_232_acc: 0.9168 - dense_233_acc: 0.4301 - dense_234_acc: 0.4411 - val_loss: 3.4684 - val_dense_231_loss: 0.2663 - val_dense_232_loss: 0.2728 - val_dense_233_loss: 1.4879 - val_dense_234_loss: 1.4413 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.3812 - val_dense_234_acc: 0.4813\n",
            "Epoch 88/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8418 - dense_231_loss: 0.2435 - dense_232_loss: 0.2342 - dense_233_loss: 1.6611 - dense_234_loss: 1.7030 - dense_231_acc: 0.9074 - dense_232_acc: 0.9074 - dense_233_acc: 0.4239 - dense_234_acc: 0.3972 - val_loss: 3.5241 - val_dense_231_loss: 0.2630 - val_dense_232_loss: 0.2745 - val_dense_233_loss: 1.5236 - val_dense_234_loss: 1.4631 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8812 - val_dense_233_acc: 0.3625 - val_dense_234_acc: 0.4562\n",
            "Epoch 89/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8564 - dense_231_loss: 0.2347 - dense_232_loss: 0.2335 - dense_233_loss: 1.6691 - dense_234_loss: 1.7192 - dense_231_acc: 0.9121 - dense_232_acc: 0.9089 - dense_233_acc: 0.4223 - dense_234_acc: 0.4097 - val_loss: 3.5295 - val_dense_231_loss: 0.2650 - val_dense_232_loss: 0.2679 - val_dense_233_loss: 1.5263 - val_dense_234_loss: 1.4703 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4437 - val_dense_234_acc: 0.5188\n",
            "Epoch 90/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.8552 - dense_231_loss: 0.2467 - dense_232_loss: 0.2515 - dense_233_loss: 1.6361 - dense_234_loss: 1.7210 - dense_231_acc: 0.8980 - dense_232_acc: 0.9058 - dense_233_acc: 0.4317 - dense_234_acc: 0.3956 - val_loss: 3.3656 - val_dense_231_loss: 0.2579 - val_dense_232_loss: 0.2595 - val_dense_233_loss: 1.4683 - val_dense_234_loss: 1.3798 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4000 - val_dense_234_acc: 0.5687\n",
            "Epoch 91/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.7661 - dense_231_loss: 0.2330 - dense_232_loss: 0.2333 - dense_233_loss: 1.5939 - dense_234_loss: 1.7059 - dense_231_acc: 0.9058 - dense_232_acc: 0.9058 - dense_233_acc: 0.4647 - dense_234_acc: 0.4239 - val_loss: 3.4237 - val_dense_231_loss: 0.2610 - val_dense_232_loss: 0.2680 - val_dense_233_loss: 1.4393 - val_dense_234_loss: 1.4555 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.5375\n",
            "Epoch 92/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6911 - dense_231_loss: 0.2019 - dense_232_loss: 0.2056 - dense_233_loss: 1.6384 - dense_234_loss: 1.6452 - dense_231_acc: 0.9246 - dense_232_acc: 0.9215 - dense_233_acc: 0.4129 - dense_234_acc: 0.4317 - val_loss: 3.2298 - val_dense_231_loss: 0.2522 - val_dense_232_loss: 0.2555 - val_dense_233_loss: 1.4503 - val_dense_234_loss: 1.2719 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4250 - val_dense_234_acc: 0.6125\n",
            "Epoch 93/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6773 - dense_231_loss: 0.2261 - dense_232_loss: 0.2215 - dense_233_loss: 1.5154 - dense_234_loss: 1.7143 - dense_231_acc: 0.9105 - dense_232_acc: 0.9152 - dense_233_acc: 0.4851 - dense_234_acc: 0.4050 - val_loss: 3.4388 - val_dense_231_loss: 0.2589 - val_dense_232_loss: 0.2620 - val_dense_233_loss: 1.5364 - val_dense_234_loss: 1.3815 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.3812 - val_dense_234_acc: 0.5437\n",
            "Epoch 94/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.7414 - dense_231_loss: 0.2383 - dense_232_loss: 0.2360 - dense_233_loss: 1.5568 - dense_234_loss: 1.7103 - dense_231_acc: 0.9137 - dense_232_acc: 0.9121 - dense_233_acc: 0.4537 - dense_234_acc: 0.4160 - val_loss: 3.4512 - val_dense_231_loss: 0.2733 - val_dense_232_loss: 0.2802 - val_dense_233_loss: 1.4685 - val_dense_234_loss: 1.4291 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9062 - val_dense_233_acc: 0.4437 - val_dense_234_acc: 0.5250\n",
            "Epoch 95/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6963 - dense_231_loss: 0.2254 - dense_232_loss: 0.2183 - dense_233_loss: 1.5779 - dense_234_loss: 1.6747 - dense_231_acc: 0.9058 - dense_232_acc: 0.9121 - dense_233_acc: 0.4568 - dense_234_acc: 0.4427 - val_loss: 3.3449 - val_dense_231_loss: 0.2524 - val_dense_232_loss: 0.2593 - val_dense_233_loss: 1.4857 - val_dense_234_loss: 1.3476 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4000 - val_dense_234_acc: 0.5687\n",
            "Epoch 96/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6766 - dense_231_loss: 0.2272 - dense_232_loss: 0.2187 - dense_233_loss: 1.5921 - dense_234_loss: 1.6385 - dense_231_acc: 0.9074 - dense_232_acc: 0.9121 - dense_233_acc: 0.4505 - dense_234_acc: 0.4553 - val_loss: 3.3194 - val_dense_231_loss: 0.2883 - val_dense_232_loss: 0.2996 - val_dense_233_loss: 1.4320 - val_dense_234_loss: 1.2995 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4625 - val_dense_234_acc: 0.5750\n",
            "Epoch 97/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6579 - dense_231_loss: 0.2285 - dense_232_loss: 0.2210 - dense_233_loss: 1.6011 - dense_234_loss: 1.6073 - dense_231_acc: 0.9262 - dense_232_acc: 0.9262 - dense_233_acc: 0.4662 - dense_234_acc: 0.4647 - val_loss: 3.2959 - val_dense_231_loss: 0.2533 - val_dense_232_loss: 0.2600 - val_dense_233_loss: 1.4982 - val_dense_234_loss: 1.2844 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8812 - val_dense_233_acc: 0.3625 - val_dense_234_acc: 0.5500\n",
            "Epoch 98/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.6056 - dense_231_loss: 0.2038 - dense_232_loss: 0.1949 - dense_233_loss: 1.5887 - dense_234_loss: 1.6182 - dense_231_acc: 0.9152 - dense_232_acc: 0.9168 - dense_233_acc: 0.4710 - dense_234_acc: 0.4490 - val_loss: 3.3104 - val_dense_231_loss: 0.2688 - val_dense_232_loss: 0.2744 - val_dense_233_loss: 1.4666 - val_dense_234_loss: 1.3006 - val_dense_231_acc: 0.9000 - val_dense_232_acc: 0.9000 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.5813\n",
            "Epoch 99/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.5889 - dense_231_loss: 0.2154 - dense_232_loss: 0.2063 - dense_233_loss: 1.5384 - dense_234_loss: 1.6288 - dense_231_acc: 0.9215 - dense_232_acc: 0.9246 - dense_233_acc: 0.4647 - dense_234_acc: 0.4380 - val_loss: 3.3287 - val_dense_231_loss: 0.2607 - val_dense_232_loss: 0.2641 - val_dense_233_loss: 1.4397 - val_dense_234_loss: 1.3642 - val_dense_231_acc: 0.9062 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4500 - val_dense_234_acc: 0.5125\n",
            "Epoch 100/100\n",
            "637/637 [==============================] - 3s 5ms/step - loss: 3.5724 - dense_231_loss: 0.2200 - dense_232_loss: 0.2213 - dense_233_loss: 1.5689 - dense_234_loss: 1.5622 - dense_231_acc: 0.9137 - dense_232_acc: 0.9042 - dense_233_acc: 0.4772 - dense_234_acc: 0.4600 - val_loss: 3.3373 - val_dense_231_loss: 0.2672 - val_dense_232_loss: 0.2670 - val_dense_233_loss: 1.4747 - val_dense_234_loss: 1.3284 - val_dense_231_acc: 0.8938 - val_dense_232_acc: 0.8938 - val_dense_233_acc: 0.4313 - val_dense_234_acc: 0.5375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7fb06d6e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "metadata": {
        "id": "5FiFJmbbwICH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prediction "
      ]
    },
    {
      "metadata": {
        "id": "KGb2H9N9qAHh",
        "colab_type": "code",
        "outputId": "d5cd5e35-2e12-4987-944e-dbf8b38ecff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "pred_l = ['23-Dec-1955', '24 Dec 1960', 'December 15 2003', 'January of 15 90', '1995 1 Apr', \n",
        "          '15/01/2000', '19 May 1999', '01-02-90', '2 October 1993', '25 05 83']\n",
        "\n",
        "pred_l = [x.lower() for x in pred_l]\n",
        "\n",
        "#print(pred_l)\n",
        "pred_m = len(pred_l)\n",
        "print(\"TOtal size of prediction list: \", pred_m)\n",
        "\n",
        "pred_x = np.zeros(shape = (pred_m, MAX_INPUT_SEQ_LEN, VOCAB_LEN))\n",
        "\n",
        "for i in range(len(pred_l)):\n",
        "    for j,k in enumerate(pred_l[i]):\n",
        "      try:\n",
        "        pred_x[i][j][char_to_ix[k]] = 1\n",
        "      except:\n",
        "        print(\"i {} j {} k {}\".format( i, j, k))\n",
        "        \n",
        " "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOtal size of prediction list:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lPQ63oRr5mb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ce4e0bab-c02b-4287-a78e-a598f76b4762"
      },
      "cell_type": "code",
      "source": [
        "o_input = np.zeros(shape =(pred_m,activation_size))\n",
        "prediction = model.predict([pred_x,o_input])\n",
        "print(len(prediction))\n",
        "print(prediction[0].shape)\n",
        "\n",
        "\n",
        "for i in range(pred_m):\n",
        "  dates = []\n",
        "  for j in range(OUTPUT_SIZE):\n",
        "    pos = np.argmax(prediction[j][i])\n",
        "    \n",
        "    \n",
        "    #char = [ix_to_char[k] for k in pos]\n",
        "    dates.append(ix_to_char[pos])\n",
        "  #dates.join(' ')\n",
        "  print(dates)\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "(10, 40)\n",
            "[':', '1', '3', '/']\n",
            "['\\t', '-', 'b', '\\n']\n",
            "['r', '1', 'r', ':']\n",
            "['\\t', 'j', 'n', '\\n']\n",
            "['\\t', 's', '-', '3']\n",
            "['-', '-', 'r', 'm']\n",
            "['m', 's', 'b', '3']\n",
            "['-', '1', 'r', 'm']\n",
            "['p', 'j', 'b', '\\n']\n",
            "['p', 's', '\\t', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PTxlREaEGO14",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's define the prediction modelling\n",
        "\n",
        "Prediction will have two Modes - Encoder model and decoder model.\n",
        "\n",
        "Encoder model will predict the final tensor representing the input text.\n",
        "Predicted tensor from Encoder will be used as input for decoder model. \n",
        "\n",
        "First cell of decoder will have final states from encoder model and input as zero or <SOS> token. The prediction from first cell is our predicted character. The h,s from this cell will be used input to subsequent cell till desired length or <EOS> token is reached."
      ]
    },
    {
      "metadata": {
        "id": "tmCgzgPyT39i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}